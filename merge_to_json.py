#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•æ„Ÿè¯åº“åˆå¹¶å’ŒJSONè½¬æ¢è„šæœ¬
Sensitive Lexicon Merging and JSON Conversion Script

è¯¥è„šæœ¬ç”¨äºï¼š
1. å°†Vocabularyæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ•æ„Ÿè¯åº“æ–‡ä»¶åˆå¹¶åˆ°merged_sensitive_words.txt
2. å°†merged_sensitive_words.txtè½¬æ¢ä¸ºJSONæ ¼å¼
"""

import os
import json
import re
import logging
from datetime import datetime
from typing import Set, List, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('merge_to_json.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class SensitiveWordMerger:
    """æ•æ„Ÿè¯åˆå¹¶å’ŒJSONè½¬æ¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.vocabulary_dir = "Vocabulary"
        self.merged_file = "merged_sensitive_words.txt"
        self.json_file = "merged_sensitive_words.json"
    
    def read_vocabulary_files(self) -> Set[str]:
        """è¯»å–å¹¶åˆå¹¶æ‰€æœ‰è¯æ±‡æ–‡ä»¶"""
        logger.info("å¼€å§‹è¯»å–è¯æ±‡æ–‡ä»¶...")
        all_words = set()
        
        if not os.path.exists(self.vocabulary_dir):
            logger.error(f"è¯æ±‡ç›®å½• {self.vocabulary_dir} ä¸å­˜åœ¨")
            return all_words
        
        file_count = 0
        total_words_read = 0
        
        for filename in os.listdir(self.vocabulary_dir):
            if filename.endswith('.txt'):
                filepath = os.path.join(self.vocabulary_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # å¤„ç†ä¸åŒçš„åˆ†éš”ç¬¦
                        if '\n' in content:
                            words = content.split('\n')
                        else:
                            # å¤„ç†å¯èƒ½çš„ç©ºæ ¼æˆ–å…¶ä»–åˆ†éš”ç¬¦
                            words = re.split(r'[\s,ï¼Œã€]+', content)
                        
                        # æ¸…ç†è¯æ±‡
                        file_words = 0
                        for word in words:
                            word = word.strip()
                            # è·³è¿‡æ³¨é‡Šè¡Œã€ç©ºè¡Œå’Œç©ºç™½å­—ç¬¦
                            if word and not word.startswith('#') and len(word) > 0:
                                all_words.add(word)
                                file_words += 1
                        
                        total_words_read += file_words
                        file_count += 1
                        logger.info(f"è¯»å–æ–‡ä»¶ {filename}: {file_words} ä¸ªè¯æ±‡")
                        
                except Exception as e:
                    logger.error(f"è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        
        logger.info(f"æ€»è®¡è¯»å– {file_count} ä¸ªæ–‡ä»¶ï¼Œ{total_words_read} ä¸ªåŸå§‹è¯æ±‡ï¼Œå»é‡å {len(all_words)} ä¸ªè¯æ±‡")
        return all_words
    
    def create_merged_file(self, words: Set[str]) -> bool:
        """åˆ›å»ºåˆå¹¶çš„æ•æ„Ÿè¯æ–‡ä»¶"""
        logger.info(f"åˆ›å»ºåˆå¹¶æ–‡ä»¶ {self.merged_file}...")
        
        try:
            # æŒ‰å­—æ¯é¡ºåºæ’åº
            sorted_words = sorted(list(words))
            
            with open(self.merged_file, 'w', encoding='utf-8') as f:
                # æ·»åŠ æ–‡ä»¶å¤´æ³¨é‡Š
                f.write(f"# æ•æ„Ÿè¯åº“åˆå¹¶æ–‡ä»¶\n")
                f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# æ€»è¯æ±‡æ•°: {len(sorted_words)}\n")
                f.write(f"# æ¥æº: Vocabularyç›®å½•ä¸‹çš„æ‰€æœ‰.txtæ–‡ä»¶\n")
                f.write(f"#\n")
                
                # å†™å…¥æ‰€æœ‰è¯æ±‡
                for word in sorted_words:
                    f.write(word + '\n')
            
            logger.info(f"æˆåŠŸåˆ›å»º {self.merged_file}ï¼ŒåŒ…å« {len(sorted_words)} ä¸ªè¯æ±‡")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåˆå¹¶æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def read_merged_file(self) -> List[str]:
        """è¯»å–åˆå¹¶æ–‡ä»¶ä¸­çš„è¯æ±‡"""
        logger.info(f"è¯»å–åˆå¹¶æ–‡ä»¶ {self.merged_file}...")
        words = []
        
        if not os.path.exists(self.merged_file):
            logger.error(f"åˆå¹¶æ–‡ä»¶ {self.merged_file} ä¸å­˜åœ¨")
            return words
        
        try:
            with open(self.merged_file, 'r', encoding='utf-8') as f:
                for line in f:
                    word = line.strip()
                    # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
                    if word and not word.startswith('#'):
                        words.append(word)
            
            logger.info(f"ä»åˆå¹¶æ–‡ä»¶è¯»å–åˆ° {len(words)} ä¸ªè¯æ±‡")
            return words
            
        except Exception as e:
            logger.error(f"è¯»å–åˆå¹¶æ–‡ä»¶å¤±è´¥: {e}")
            return words
    
    def create_json_file(self, words: List[str]) -> bool:
        """åˆ›å»ºJSONæ ¼å¼æ–‡ä»¶"""
        logger.info(f"åˆ›å»ºJSONæ–‡ä»¶ {self.json_file}...")
        
        try:
            # åˆ›å»ºJSONæ•°æ®ç»“æ„
            json_data = {
                "metadata": {
                    "source_file": self.merged_file,
                    "converted_time": datetime.now().strftime('%Y-%m-%dT%H:%M:%S'),
                    "total_words": len(words),
                    "description": "æ•æ„Ÿè¯åº“ - æ‰€æœ‰è¯æ±‡çš„ç®€å•åˆ—è¡¨"
                },
                "words": words
            }
            
            # å†™å…¥JSONæ–‡ä»¶ï¼Œç¡®ä¿æ”¯æŒä¸­æ–‡å­—ç¬¦
            with open(self.json_file, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æˆåŠŸåˆ›å»º {self.json_file}ï¼ŒåŒ…å« {len(words)} ä¸ªè¯æ±‡")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºJSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def validate_json_file(self) -> bool:
        """éªŒè¯JSONæ–‡ä»¶æ ¼å¼æ­£ç¡®æ€§"""
        logger.info("éªŒè¯JSONæ–‡ä»¶æ ¼å¼...")
        
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # éªŒè¯åŸºæœ¬ç»“æ„
            if 'metadata' not in data or 'words' not in data:
                logger.error("JSONæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„å­—æ®µ")
                return False
            
            # éªŒè¯metadataå­—æ®µ
            required_fields = ['source_file', 'converted_time', 'total_words', 'description']
            for field in required_fields:
                if field not in data['metadata']:
                    logger.error(f"metadataç¼ºå°‘å­—æ®µ: {field}")
                    return False
            
            # éªŒè¯è¯æ±‡æ•°é‡
            if data['metadata']['total_words'] != len(data['words']):
                logger.error("è¯æ±‡æ•°é‡ä¸åŒ¹é…")
                return False
            
            logger.info("JSONæ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"JSONæ–‡ä»¶æ ¼å¼éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run(self) -> bool:
        """è¿è¡Œå®Œæ•´çš„åˆå¹¶å’Œè½¬æ¢æµç¨‹"""
        logger.info("å¼€å§‹æ•æ„Ÿè¯åº“åˆå¹¶å’ŒJSONè½¬æ¢ä»»åŠ¡...")
        start_time = datetime.now()
        
        try:
            # æ­¥éª¤1: è¯»å–å¹¶åˆå¹¶æ‰€æœ‰è¯æ±‡æ–‡ä»¶
            all_words = self.read_vocabulary_files()
            if not all_words:
                logger.error("æ²¡æœ‰è¯»å–åˆ°ä»»ä½•è¯æ±‡")
                return False
            
            # æ­¥éª¤2: åˆ›å»ºåˆå¹¶æ–‡ä»¶
            if not self.create_merged_file(all_words):
                logger.error("åˆ›å»ºåˆå¹¶æ–‡ä»¶å¤±è´¥")
                return False
            
            # æ­¥éª¤3: ä»åˆå¹¶æ–‡ä»¶è¯»å–è¯æ±‡
            words = self.read_merged_file()
            if not words:
                logger.error("ä»åˆå¹¶æ–‡ä»¶è¯»å–è¯æ±‡å¤±è´¥")
                return False
            
            # æ­¥éª¤4: åˆ›å»ºJSONæ–‡ä»¶
            if not self.create_json_file(words):
                logger.error("åˆ›å»ºJSONæ–‡ä»¶å¤±è´¥")
                return False
            
            # æ­¥éª¤5: éªŒè¯JSONæ–‡ä»¶
            if not self.validate_json_file():
                logger.error("JSONæ–‡ä»¶éªŒè¯å¤±è´¥")
                return False
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            logger.info(f"ä»»åŠ¡å®Œæˆ! è€—æ—¶: {duration}")
            logger.info(f"ç”Ÿæˆæ–‡ä»¶: {self.merged_file}, {self.json_file}")
            
            return True
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return False


def main():
    """ä¸»å‡½æ•°"""
    merger = SensitiveWordMerger()
    success = merger.run()
    
    if success:
        print("âœ… æ•æ„Ÿè¯åº“åˆå¹¶å’ŒJSONè½¬æ¢ä»»åŠ¡å®Œæˆ!")
        print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {merger.merged_file}")
        print(f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶: {merger.json_file}")
    else:
        print("âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())