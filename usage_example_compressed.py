#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‹ç¼©JSONæ–‡ä»¶ä½¿ç”¨ç¤ºä¾‹
Usage Example for Compressed JSON Files

æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨å‹ç¼©åçš„æ•æ„Ÿè¯JSONæ–‡ä»¶
"""

import json
import gzip
import time
from typing import Set, List

class CompressedSensitiveWordLoader:
    """å‹ç¼©æ•æ„Ÿè¯æ–‡ä»¶åŠ è½½å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŠ è½½å™¨"""
        self.words = set()
        self.metadata = {}
    
    def load_original_format(self, filepath: str = "merged_sensitive_words.json"):
        """åŠ è½½åŸå§‹æ ¼å¼æ–‡ä»¶
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“– åŠ è½½åŸå§‹æ ¼å¼æ–‡ä»¶: {filepath}")
        start_time = time.time()
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.words = set(data['words'])
        self.metadata = {k: v for k, v in data.items() if k != 'words'}
        
        load_time = time.time() - start_time
        print(f"âœ… åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.3f}ç§’ï¼Œè¯æ±‡æ•°é‡: {len(self.words):,}")
        return load_time
    
    def load_compressed_format(self, filepath: str = "merged_sensitive_words_compressed.json"):
        """åŠ è½½JSONå‹ç¼©æ ¼å¼æ–‡ä»¶
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“– åŠ è½½JSONå‹ç¼©æ ¼å¼æ–‡ä»¶: {filepath}")
        start_time = time.time()
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.words = set(data['words'])
        self.metadata = {k: v for k, v in data.items() if k != 'words'}
        
        load_time = time.time() - start_time
        print(f"âœ… åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.3f}ç§’ï¼Œè¯æ±‡æ•°é‡: {len(self.words):,}")
        return load_time
    
    def load_gzip_format(self, filepath: str = "merged_sensitive_words_compressed.json.gz"):
        """åŠ è½½GZIPå‹ç¼©æ ¼å¼æ–‡ä»¶
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ“– åŠ è½½GZIPå‹ç¼©æ ¼å¼æ–‡ä»¶: {filepath}")
        start_time = time.time()
        
        with gzip.open(filepath, 'rt', encoding='utf-8') as f:
            data = json.load(f)
        
        self.words = set(data['words'])
        self.metadata = {k: v for k, v in data.items() if k != 'words'}
        
        load_time = time.time() - start_time
        print(f"âœ… åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.3f}ç§’ï¼Œè¯æ±‡æ•°é‡: {len(self.words):,}")
        return load_time
    
    def contains_sensitive_word(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
        
        Args:
            text: å¾…æ£€æŸ¥çš„æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
        """
        text_lower = text.lower()
        return any(word.lower() in text_lower for word in self.words)
    
    def find_sensitive_words(self, text: str) -> List[str]:
        """æŸ¥æ‰¾æ–‡æœ¬ä¸­çš„æ‰€æœ‰æ•æ„Ÿè¯
        
        Args:
            text: å¾…æ£€æŸ¥çš„æ–‡æœ¬
            
        Returns:
            æ‰¾åˆ°çš„æ•æ„Ÿè¯åˆ—è¡¨
        """
        text_lower = text.lower()
        found_words = []
        
        for word in self.words:
            if word.lower() in text_lower:
                found_words.append(word)
        
        return found_words
    
    def print_metadata(self):
        """æ‰“å°å…ƒæ•°æ®ä¿¡æ¯"""
        print("\nğŸ“‹ æ•æ„Ÿè¯åº“å…ƒæ•°æ®:")
        for key, value in self.metadata.items():
            if key == 'categories':
                print(f"  ğŸ“‚ {key}: {list(value.keys())}")
            else:
                print(f"  ğŸ“ {key}: {value}")

def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("ğŸš€ æ•æ„Ÿè¯åº“åŠ è½½æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    
    loader = CompressedSensitiveWordLoader()
    
    # æµ‹è¯•åŸå§‹æ ¼å¼
    time1 = loader.load_original_format()
    
    # æµ‹è¯•JSONå‹ç¼©æ ¼å¼
    time2 = loader.load_compressed_format()
    
    # æµ‹è¯•GZIPæ ¼å¼
    time3 = loader.load_gzip_format()
    
    # æ˜¾ç¤ºå…ƒæ•°æ®
    loader.print_metadata()
    
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"  åŸå§‹æ ¼å¼:    {time1:.3f}ç§’")
    print(f"  JSONå‹ç¼©:    {time2:.3f}ç§’ (ç›¸å¯¹åŸå§‹: {time2/time1*100:.1f}%)")
    print(f"  GZIPå‹ç¼©:    {time3:.3f}ç§’ (ç›¸å¯¹åŸå§‹: {time3/time1*100:.1f}%)")
    
    return loader

def usage_example():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ§ª æ•æ„Ÿè¯æ£€æµ‹ä½¿ç”¨ç¤ºä¾‹")
    print("="*60)
    
    # åŠ è½½å‹ç¼©ç‰ˆæœ¬ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼‰
    loader = CompressedSensitiveWordLoader()
    loader.load_compressed_format()
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„æ–‡æœ¬å†…å®¹",
        "åŒ…å«æ”¿æ²»æ•æ„Ÿè¯æ±‡çš„å†…å®¹",
        "è¿™é‡Œæœ‰ä¸€äº›ä¸å½“è¨€è®º",
        "æ­£å¸¸çš„æŠ€æœ¯è®¨è®ºå†…å®¹"
    ]
    
    print("ğŸ” æ•æ„Ÿè¯æ£€æµ‹ç»“æœ:")
    for i, text in enumerate(test_texts, 1):
        print(f"\n  æµ‹è¯•æ–‡æœ¬ {i}: {text}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿè¯
        has_sensitive = loader.contains_sensitive_word(text)
        print(f"  åŒ…å«æ•æ„Ÿè¯: {'âŒ æ˜¯' if has_sensitive else 'âœ… å¦'}")
        
        # æŸ¥æ‰¾å…·ä½“çš„æ•æ„Ÿè¯
        if has_sensitive:
            found_words = loader.find_sensitive_words(text)
            print(f"  æ‰¾åˆ°çš„æ•æ„Ÿè¯: {found_words[:3]}{'...' if len(found_words) > 3 else ''}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å‹ç¼©JSONæ–‡ä»¶ä½¿ç”¨ç¤ºä¾‹æ¼”ç¤º")
    print("="*80)
    
    try:
        # æ€§èƒ½å¯¹æ¯”
        loader = performance_comparison()
        
        # ä½¿ç”¨ç¤ºä¾‹
        usage_example()
        
        print(f"\nğŸ’¡ é›†æˆå»ºè®®:")
        print(f"  1. å¼€å‘ç¯å¢ƒ: ä½¿ç”¨åŸå§‹æ ¼å¼ï¼Œä¾¿äºè°ƒè¯•")
        print(f"  2. ç”Ÿäº§ç¯å¢ƒ: ä½¿ç”¨JSONå‹ç¼©ç‰ˆæœ¬ï¼Œå‡å°‘å†…å­˜å ç”¨")
        print(f"  3. å­˜å‚¨ä¼ è¾“: ä½¿ç”¨GZIPç‰ˆæœ¬ï¼Œæœ€å¤§åŒ–ç©ºé—´èŠ‚çœ")
        print("="*80)
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()