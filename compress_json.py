#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONæ–‡ä»¶å‹ç¼©è„šæœ¬
JSON File Compression Script

è¯¥è„šæœ¬ç”¨äºå‹ç¼©merged_sensitive_words.jsonæ–‡ä»¶ï¼Œä¼˜åŒ–æ–‡ä»¶å¤§å°ï¼Œ
åŒæ—¶ä¿æŒæ•°æ®å®Œæ•´æ€§å’ŒJSONæ ¼å¼çš„æœ‰æ•ˆæ€§ã€‚
"""

import os
import json
import gzip
import shutil
import logging
from datetime import datetime
from typing import Dict, Any, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class JSONCompressor:
    """JSONå‹ç¼©å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å‹ç¼©å™¨"""
        self.compression_stats = {}
    
    def get_file_size(self, filepath: str) -> int:
        """è·å–æ–‡ä»¶å¤§å°
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        return os.path.getsize(filepath) if os.path.exists(filepath) else 0
    
    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º
        
        Args:
            size_bytes: å­—èŠ‚æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„å¤§å°å­—ç¬¦ä¸²
        """
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    
    def validate_json_integrity(self, original_file: str, compressed_file: str) -> bool:
        """éªŒè¯å‹ç¼©åJSONçš„å®Œæ•´æ€§
        
        Args:
            original_file: åŸå§‹æ–‡ä»¶è·¯å¾„
            compressed_file: å‹ç¼©æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦å®Œæ•´
        """
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶
            with open(original_file, 'r', encoding='utf-8') as f:
                original_data = json.load(f)
            
            # è¯»å–å‹ç¼©æ–‡ä»¶
            with open(compressed_file, 'r', encoding='utf-8') as f:
                compressed_data = json.load(f)
            
            # æ¯”è¾ƒå…³é”®å­—æ®µ
            if original_data.get('totalCount') != compressed_data.get('totalCount'):
                logger.error("è¯æ±‡æ€»æ•°ä¸åŒ¹é…")
                return False
            
            if len(original_data.get('words', [])) != len(compressed_data.get('words', [])):
                logger.error("è¯æ±‡åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…")
                return False
            
            # æ¯”è¾ƒè¯æ±‡å†…å®¹ï¼ˆæ’åºåæ¯”è¾ƒä»¥é¿å…é¡ºåºé—®é¢˜ï¼‰
            original_words = sorted(original_data.get('words', []))
            compressed_words = sorted(compressed_data.get('words', []))
            
            if original_words != compressed_words:
                logger.error("è¯æ±‡å†…å®¹ä¸åŒ¹é…")
                return False
            
            logger.info("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def compress_json_format(self, input_file: str, output_file: str) -> Tuple[int, int]:
        """å‹ç¼©JSONæ ¼å¼ï¼ˆç§»é™¤ç©ºç™½å­—ç¬¦ï¼‰
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            (åŸå§‹å¤§å°, å‹ç¼©åå¤§å°)
        """
        try:
            # è¯»å–JSONæ•°æ®
            with open(input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ä»¥ç´§å‡‘æ ¼å¼ä¿å­˜ï¼ˆæ— ç¼©è¿›ï¼Œæ— ç©ºæ ¼ï¼‰
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, separators=(',', ':'))
            
            original_size = self.get_file_size(input_file)
            compressed_size = self.get_file_size(output_file)
            
            return original_size, compressed_size
            
        except Exception as e:
            logger.error(f"âŒ JSONæ ¼å¼å‹ç¼©å¤±è´¥: {e}")
            raise
    
    def create_gzip_version(self, input_file: str, output_file: str) -> int:
        """åˆ›å»ºGZIPå‹ç¼©ç‰ˆæœ¬
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆ.gzæ–‡ä»¶ï¼‰
            
        Returns:
            å‹ç¼©åå¤§å°
        """
        try:
            with open(input_file, 'rb') as f_in:
                with gzip.open(output_file, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            return self.get_file_size(output_file)
            
        except Exception as e:
            logger.error(f"âŒ GZIPå‹ç¼©å¤±è´¥: {e}")
            raise
    
    def compress_file(self, input_file: str) -> Dict[str, Any]:
        """å‹ç¼©æ–‡ä»¶å¹¶ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
        """
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        
        logger.info(f"å¼€å§‹å‹ç¼©æ–‡ä»¶: {input_file}")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(input_file)[0]
        compressed_file = f"{base_name}_compressed.json"
        gzip_file = f"{base_name}_compressed.json.gz"
        
        # è·å–åŸå§‹æ–‡ä»¶å¤§å°
        original_size = self.get_file_size(input_file)
        logger.info(f"ğŸ“ åŸå§‹æ–‡ä»¶å¤§å°: {self.format_size(original_size)}")
        
        # æ‰§è¡ŒJSONæ ¼å¼å‹ç¼©
        logger.info("ğŸ—œï¸ æ‰§è¡ŒJSONæ ¼å¼å‹ç¼©...")
        original_size, compressed_size = self.compress_json_format(input_file, compressed_file)
        
        # åˆ›å»ºGZIPç‰ˆæœ¬
        logger.info("ğŸ—œï¸ åˆ›å»ºGZIPå‹ç¼©ç‰ˆæœ¬...")
        gzip_size = self.create_gzip_version(compressed_file, gzip_file)
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        logger.info("ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        if not self.validate_json_integrity(input_file, compressed_file):
            raise Exception("æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥")
        
        # è®¡ç®—å‹ç¼©æ¯”ä¾‹
        json_compression_ratio = (1 - compressed_size / original_size) * 100
        gzip_compression_ratio = (1 - gzip_size / original_size) * 100
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = {
            "timestamp": datetime.now().isoformat(),
            "original_file": input_file,
            "original_size": original_size,
            "original_size_formatted": self.format_size(original_size),
            "compressed_file": compressed_file,
            "compressed_size": compressed_size,
            "compressed_size_formatted": self.format_size(compressed_size),
            "gzip_file": gzip_file,
            "gzip_size": gzip_size,
            "gzip_size_formatted": self.format_size(gzip_size),
            "json_compression_ratio": json_compression_ratio,
            "gzip_compression_ratio": gzip_compression_ratio,
            "space_saved_json": original_size - compressed_size,
            "space_saved_gzip": original_size - gzip_size
        }
        
        self.compression_stats = stats
        return stats
    
    def print_compression_report(self, stats: Dict[str, Any]):
        """æ‰“å°å‹ç¼©æŠ¥å‘Š
        
        Args:
            stats: å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
        """
        print("\n" + "="*60)
        print("ğŸ“Š JSONæ–‡ä»¶å‹ç¼©æŠ¥å‘Š")
        print("="*60)
        print(f"ğŸ• å‹ç¼©æ—¶é—´: {stats['timestamp']}")
        print(f"ğŸ“„ åŸå§‹æ–‡ä»¶: {stats['original_file']}")
        print(f"ğŸ“ åŸå§‹å¤§å°: {stats['original_size_formatted']} ({stats['original_size']:,} å­—èŠ‚)")
        print()
        print("ğŸ—œï¸ JSONæ ¼å¼å‹ç¼©ç»“æœ:")
        print(f"  ğŸ“„ å‹ç¼©æ–‡ä»¶: {stats['compressed_file']}")
        print(f"  ğŸ“ å‹ç¼©å¤§å°: {stats['compressed_size_formatted']} ({stats['compressed_size']:,} å­—èŠ‚)")
        print(f"  ğŸ“‰ å‹ç¼©æ¯”ä¾‹: {stats['json_compression_ratio']:.1f}%")
        print(f"  ğŸ’¾ èŠ‚çœç©ºé—´: {self.format_size(stats['space_saved_json'])}")
        print()
        print("ğŸ—œï¸ GZIPå‹ç¼©ç»“æœ:")
        print(f"  ğŸ“„ å‹ç¼©æ–‡ä»¶: {stats['gzip_file']}")
        print(f"  ğŸ“ å‹ç¼©å¤§å°: {stats['gzip_size_formatted']} ({stats['gzip_size']:,} å­—èŠ‚)")
        print(f"  ğŸ“‰ å‹ç¼©æ¯”ä¾‹: {stats['gzip_compression_ratio']:.1f}%")
        print(f"  ğŸ’¾ èŠ‚çœç©ºé—´: {self.format_size(stats['space_saved_gzip'])}")
        print()
        print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
        if stats['json_compression_ratio'] > 30:
            print("  âœ… JSONæ ¼å¼å‹ç¼©æ•ˆæœæ˜¾è‘—ï¼Œå»ºè®®ä½¿ç”¨å‹ç¼©ç‰ˆæœ¬")
        else:
            print("  âš ï¸ JSONæ ¼å¼å‹ç¼©æ•ˆæœä¸€èˆ¬")
        
        if stats['gzip_compression_ratio'] > 50:
            print("  âœ… GZIPå‹ç¼©æ•ˆæœä¼˜ç§€ï¼Œé€‚åˆå­˜å‚¨å’Œä¼ è¾“")
        else:
            print("  âš ï¸ GZIPå‹ç¼©æ•ˆæœä¸€èˆ¬")
        print("="*60)
    
    def save_compression_report(self, stats: Dict[str, Any], report_file: str = "compression_report.json"):
        """ä¿å­˜å‹ç¼©æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            stats: å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
            report_file: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“‹ å‹ç¼©æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # é»˜è®¤è¾“å…¥æ–‡ä»¶
    input_file = "merged_sensitive_words.json"
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        logger.info("è¯·å…ˆè¿è¡Œ generate_merged_json.py ç”Ÿæˆåˆå¹¶æ–‡ä»¶")
        return
    
    # åˆ›å»ºå‹ç¼©å™¨å¹¶æ‰§è¡Œå‹ç¼©
    compressor = JSONCompressor()
    
    try:
        # æ‰§è¡Œå‹ç¼©
        stats = compressor.compress_file(input_file)
        
        # æ‰“å°æŠ¥å‘Š
        compressor.print_compression_report(stats)
        
        # ä¿å­˜æŠ¥å‘Š
        compressor.save_compression_report(stats)
        
        logger.info("ğŸ‰ å‹ç¼©ä»»åŠ¡å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ å‹ç¼©è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()